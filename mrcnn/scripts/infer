#!/usr/bin/env python
# coding: utf-8

import os
import sys
import numpy as np
import click
import tqdm
import skimage.io
import traceback

# Root directory of the project
# sys.path.append(ROOT_DIR)  # To find local version of the library
import mrcnn
from mrcnn import utils
import mrcnn.model as modellib
import mrcnn.coco as coco
from mrcnn import visualize
ROOT_DIR = path = os.path.dirname(mrcnn.__file__)
MODEL_DIR = os.path.join('.', "logs")  # TODO: handle these paths better
COCO_MODEL_PATH = os.path.join(ROOT_DIR, "mask_rcnn_coco.h5")

if not os.path.exists(COCO_MODEL_PATH):
    utils.download_trained_weights(COCO_MODEL_PATH)


CLASS_NAMES = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',
               'bus', 'train', 'truck', 'boat', 'traffic light',
               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',
               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',
               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',
               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
               'kite', 'baseball bat', 'baseball glove', 'skateboard',
               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',
               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',
               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',
               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',
               'teddy bear', 'hair drier', 'toothbrush']


def crop_image(image, box):
    ''' 
        crop image from given box anchors
        boxes are always square and centered around the object
        The box is symmetrically padded before and after to prevent 
        problems with objects close to boundaries
        
        box : [y1, x1, y2, x2]
    '''    
    y1, x1, y2, x2 = box
    w, h = image.shape[:2]
    boxw, boxh = abs(x1 - x2), abs(y1 - y2)
    delta_box = abs(boxw - boxh)
    _image = np.pad(image, ((delta_box, delta_box),
                            (delta_box, delta_box),
                            (0, 0)),
                   mode="symmetric")
    #     x1c = x1 + delta
    crop_w = delta_box
    if crop_w % 2 != 0:
        crop_w += 1
    crop_x1 = int(x1 - crop_w / 2 + delta_box)
    crop_x2 = int(x2 + crop_w / 2 + delta_box)
    crop_y1 = int(y1 - crop_w / 2 + delta_box)
    crop_y2 = int(y2 + crop_w / 2 + delta_box)
    im_crop = _image[crop_y1:crop_y2, crop_x1:crop_x2]
    return im_crop

def filter_roi(rois, _filter):
    ''' filter ROIs according to filter array (boolean list) '''
    assert rois.shape[0] == len(_filter)
    return rois[_filter, :]

def filter_scores(scores, _filter):
    ''' filter scores according to filter list '''
    assert len(scores) == len(_filter)
    return [scores[i] for i in range(len(scores)) if _filter[i]]

def filter_class_ids(class_ids, _filter):
    ''' filter scores according to filter list '''
    assert len(class_ids) == len(_filter)
    return class_ids[_filter]

def filter_masks(masks, _filter):
    ''' filter masks according to filter list '''
    assert masks.shape[-1] == len(_filter)
    return np.concatenate([masks[..., i] for i in range(len(_filter)) if _filter[i]])[..., np.newaxis]

def infer_file(f_path, model):
    ''' run mask rcnn from image provided path to image'''
    fig, ax = plt.subplots(1, 1, figsize=(8, 8))
    try:
        image_dir = os.path.dirname(f_path)
        image = skimage.io.imread(f_path)

        in_name, in_ext = os.path.splitext(os.path.basename(f_path))

        results = model.detect([image], verbose=0)

        r = results[0]

        visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'],
                                    CLASS_NAMES, r['scores'], ax=ax)

        out_dir = os.path.join(image_dir, os.pardir, "instances")
        os.makedirs(out_dir, exist_ok=True)
        out_name = ''.join(["instances_", in_name, in_ext])
        out_name = os.path.join(out_dir, out_name)
        plt.tight_layout()
        plt.savefig(out_name)


    except Exception as err:
        print("error at ", f_path)
        try:
            raise TypeError("Again !?!")
        except:
            pass

        traceback.print_tb(err.__traceback__)

def infer_folder(folder_path, model, class_names, target_class):
    files = sorted(os.listdir(folder_path))
    print(folder_path)
    for file in tqdm.tqdm(files):
        print(file)
        infer_file(os.path.join(folder_path, file), model, class_names, target_class)


from matplotlib import pyplot as plt


# TODO: add filter option to filter instances

@click.command()
@click.argument("file_or_folder")
def main(file_or_folder):
    '''
    crop out a target class in an image assuming there is only 1 instance of this class in the image.

    Usage 1 : box_crop cat.jpg cat
        --> outputs centered square crop into ./cropped/cropped_cat.jpg
        --> outputs centered mask crop into ./mask/mask_cat.jpg

    Usage 2 : box_crop frames/ cat
        --> outputs each file in frames a centered square crop into ./cropped/xx.jpg
        --> outputs each file in frames a centered mask crop into ./mask/xx.jpg
    '''
    class InferenceConfig(coco.CocoConfig):
        # Set batch size to 1 since we'll be running inference on
        # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU
        GPU_COUNT = 1
        IMAGES_PER_GPU = 1

    config = InferenceConfig()
    # Create model object in inference mode.
    model = modellib.MaskRCNN(mode="inference", model_dir=MODEL_DIR, config=config)

    # Load weights trained on MS-COCO
    model.load_weights(COCO_MODEL_PATH, by_name=True)


    if os.path.isdir(file_or_folder):
        infer_folder(file_or_folder, model)
    else:
        print(file_or_folder)
        infer_file(file_or_folder, model)




if __name__ == '__main__':
    main()